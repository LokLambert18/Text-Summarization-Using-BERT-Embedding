# Text-Summarization-Using-BERT-Embedding
This is my Capstone Project.
In this project, we present a study on extractive summarization for news. Extractive text
summarization using the conventional method was a challenging task due to the poor performance
of the sentence embedding models. However, with the invention of modern advanced deep
learning-based embedding models like transformer-based BERT, text processing in NLP
has become more practical. In this project, the use BERT sentence embedding with various
supervised learning models has been demonstrated for the extractive text summarization of
news articles taken from news datasets. For extraction summarization with supervised learning
models, first, binary class of labeled datasets is created to represent the summarization of the
news article. The implementation has been experimented with the Cornell Newsroom dataset
Created by Grusky et al., 2018.
